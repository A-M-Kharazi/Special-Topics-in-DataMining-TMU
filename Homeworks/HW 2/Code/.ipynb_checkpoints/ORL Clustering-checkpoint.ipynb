{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05db0cf2",
   "metadata": {},
   "source": [
    "# <font color = 'Blue'> ORL Clustering\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "In this excerise, we are trying to cluster ORL Dataset.  \n",
    "\n",
    "For this task, we are going to use four major clustering algorithms : Hierarchical, DBSCAN, Kmeans, and Spectral Clustering.\n",
    "\n",
    "A set of hyperparameters and optiones are pre-defined to make a unique clustering algorithms for our task. \n",
    "\n",
    "<hr> \n",
    "    \n",
    "Everything required for this exercise is available at : \n",
    "    \n",
    "    \n",
    "   \n",
    "***GitHub***  : <a href = \"https://github.com/A-M-Kharazi/Special-Topics-in-DataMining-TMU.git\" > Main (class) repo </a> \n",
    "    &nbsp;&nbsp;&nbsp;\n",
    "    <a href = \"https://github.com/A-M-Kharazi/Special-Topics-in-DataMining-TMU/tree/main/Homeworks/HW%202\" > This Document page</a>\n",
    "    \n",
    "    \n",
    "***GoogleDrive*** : <a href = \"\" > Not available ATM  </a>\n",
    "    \n",
    "    \n",
    "Make sure to run each cell (some cell's output have been cleared to decrease the size of this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a374e4d",
   "metadata": {},
   "source": [
    "#  <font color = 'Blue'> Import Libraries\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "These libraries are essential to our code so please make sure that all of them are installed or  if necessary\n",
    "<code> pip install </code> them.\n",
    "\n",
    "- numpy is used for primal data operation\n",
    "\n",
    "\n",
    "- matplotlib is used for data visualization\n",
    "\n",
    "\n",
    "- sklearn is the base of clustering algorithms\n",
    "\n",
    "    \n",
    "- Scipy is used for special matrix calculation (sparse matrix)\n",
    "    \n",
    "\n",
    "- mplot3d is to plot 3D data\n",
    "    \n",
    "    \n",
    "- PCA is Principal Component Analysis and is used to help plot our data since IRIS features are in 4D space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a478d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import orthogonal_mp as OMP\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45ba977",
   "metadata": {},
   "source": [
    "# <font color = 'Blue'> Import data\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "Making use of sklean library, we can use its fetch_olivetti_faces method to obtain our ORL dataset. If necessary, use your our method to import data. ORL is a dictionary containing data, images, target and a Describtion. \n",
    "\n",
    "In summary: ORL dataset contains 400 samples of 40 people, therefore 40 clusters is needed. Each sample is a image of 64x64, which later is flatten and saved in data. You can check the ground truth for better visualization of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0b2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORL = sklearn.datasets.fetch_olivetti_faces()\n",
    "\n",
    "data = ORL['data']\n",
    "description = ORL['DESCR']\n",
    "target = ORL['target']\n",
    "images = ORL['images']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4389c85b",
   "metadata": {},
   "source": [
    "# <font color = 'Blue'> ORL Description\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ecc54a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _olivetti_faces_dataset:\n",
      "\n",
      "The Olivetti faces dataset\n",
      "--------------------------\n",
      "\n",
      "`This dataset contains a set of face images`_ taken between April 1992 and \n",
      "April 1994 at AT&T Laboratories Cambridge. The\n",
      ":func:`sklearn.datasets.fetch_olivetti_faces` function is the data\n",
      "fetching / caching function that downloads the data\n",
      "archive from AT&T.\n",
      "\n",
      ".. _This dataset contains a set of face images: https://cam-orl.co.uk/facedatabase.html\n",
      "\n",
      "As described on the original website:\n",
      "\n",
      "    There are ten different images of each of 40 distinct subjects. For some\n",
      "    subjects, the images were taken at different times, varying the lighting,\n",
      "    facial expressions (open / closed eyes, smiling / not smiling) and facial\n",
      "    details (glasses / no glasses). All the images were taken against a dark\n",
      "    homogeneous background with the subjects in an upright, frontal position \n",
      "    (with tolerance for some side movement).\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   =====================\n",
      "    Classes                                40\n",
      "    Samples total                         400\n",
      "    Dimensionality                       4096\n",
      "    Features            real, between 0 and 1\n",
      "    =================   =====================\n",
      "\n",
      "The image is quantized to 256 grey levels and stored as unsigned 8-bit \n",
      "integers; the loader will convert these to floating point values on the \n",
      "interval [0, 1], which are easier to work with for many algorithms.\n",
      "\n",
      "The \"target\" for this database is an integer from 0 to 39 indicating the\n",
      "identity of the person pictured; however, with only 10 examples per class, this\n",
      "relatively small dataset is more interesting from an unsupervised or\n",
      "semi-supervised perspective.\n",
      "\n",
      "The original dataset consisted of 92 x 112, while the version available here\n",
      "consists of 64x64 images.\n",
      "\n",
      "When using these images, please give credit to AT&T Laboratories Cambridge.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad254f",
   "metadata": {},
   "source": [
    "# <font color = 'Blue'> Visualize Data \n",
    "\n",
    "<hr>\n",
    "\n",
    "In this section we are visualizing the ground truth. We are also using PCA(2) to plot each sample in a 2D-plane which will make visualizing the graph much simpler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "indx = 1\n",
    "for img in images:\n",
    "    ax = fig.add_subplot(20,20,indx)\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "    # add label aka target aka cluster \n",
    "    ax.text(img.shape[0]/2, img.shape[1]/2, str(target[indx-1]), fontsize = 20, color = 'red', fontweight='bold')\n",
    "    indx+=1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f73ccc",
   "metadata": {},
   "source": [
    "#  <font color = 'Blue'> Hierarchical Clustering (Complete Link - L2)\n",
    "\n",
    "<hr>\n",
    "\n",
    "    \n",
    "Using sklearn AgglomerativeClustering algorithm, we can perform hierarchical clustering on our dataset. We are using 'l2' hierarchical clustering with 'complete' linkage method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81d22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=40, affinity='l2', linkage='complete')\n",
    "\n",
    "# Fit the model on dataset\n",
    "\n",
    "clustering.fit(data)\n",
    "\n",
    "# Clustering labels\n",
    "\n",
    "Hierarchical_labels = clustering.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1f78ec",
   "metadata": {},
   "source": [
    "##  <font color = 'Blue'> Visualizing the Results and lables\n",
    "\n",
    "\n",
    "The result of hierarchical clustering can be acquired  using <code>.labels_</code> or other methods.\n",
    "\n",
    "These labels are then assigned a color and visualized in a scatter plot using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e1ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result , containg data, target and estimated cluster. \n",
    "Hierarchical_results = pd.DataFrame({'data': data.tolist(),'y' : target, 'yhat': Hierarchical_labels})\n",
    "# Sort the result so visulization is simpler \n",
    "# Sort based on the y estimate aka yhat \n",
    "# Result is the new cluster visualization\n",
    "Hierarchical_results = Hierarchical_results.sort_values(by='yhat')\n",
    "new_images = Hierarchical_results['data']\n",
    "new_targets = np.array(Hierarchical_results['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823b405c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand score : 0.9632456140350877\n",
      "Normalized Mutual Information score : 0.7510724338565746\n",
      "Fowlkes-Mallows score : 0.3877616470269056\n"
     ]
    }
   ],
   "source": [
    "# rand score\n",
    "Hierarchical_rc = metrics.rand_score(target, Hierarchical_labels)\n",
    "\n",
    "# Normalized Mutual Information\n",
    "Hierarchical_nmi = metrics.normalized_mutual_info_score(target, Hierarchical_labels)\n",
    "\n",
    "# Fowlkes-Mallows scores\n",
    "Hierarchical_fm  = metrics.fowlkes_mallows_score(target, Hierarchical_labels)\n",
    "\n",
    "\n",
    "print(f'rand score : {Hierarchical_rc}')\n",
    "print(f'Normalized Mutual Information score : {Hierarchical_nmi}')\n",
    "print(f'Fowlkes-Mallows score : {Hierarchical_fm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5943566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical result\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "indx = 1\n",
    "for img in new_images:\n",
    "    img = np.array(img).reshape(64,64)\n",
    "    ax = fig.add_subplot(20,20,indx)\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "    # add label aka target aka cluster \n",
    "    ax.text(img.shape[0]/2, img.shape[1]/2, str(new_targets[indx-1]), fontsize = 20, color = 'red', fontweight='bold')\n",
    "    indx+=1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b063aad8",
   "metadata": {},
   "source": [
    "#  <font color = 'Blue'> DBSSCAN Clustering\n",
    "\n",
    "<hr>\n",
    "\n",
    "Using sklearn DBSCAN algorithm, we can perform dbscan clustering on our dataset. Hyperparameters are set at the beginning of this exercise and different values in hyperparameters can result in different clusters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbe05138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "clustering = DBSCAN(eps=7.5, min_samples= 3)\n",
    "\n",
    "# Fit the model on dataset\n",
    "\n",
    "clustering.fit(data)\n",
    "\n",
    "# Clustering labels\n",
    "\n",
    "DBSCAN_labels = clustering.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02e835",
   "metadata": {},
   "source": [
    "##  <font color = 'Blue'> Visualizing the Results and lables\n",
    "    \n",
    "Just like hierarchical clustering, clusters can be acquired using <code>.labels_</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cee09ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result , containg data, target and estimated cluster. \n",
    "DBSCAN_results = pd.DataFrame({'data': data.tolist(),'y' : target, 'yhat': DBSCAN_labels})\n",
    "# Sort the result so visulization is simpler \n",
    "# Sort based on the y estimate aka yhat \n",
    "# Result is the new cluster visualization\n",
    "DBSCAN_results = DBSCAN_results.sort_values(by='yhat')\n",
    "new_images = DBSCAN_results['data']\n",
    "new_targets = np.array(DBSCAN_results['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ec3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand score : 0.7731077694235589\n",
      "Normalized Mutual Information score : 0.645150373185517\n",
      "Fowlkes-Mallows score : 0.2154868209451869\n"
     ]
    }
   ],
   "source": [
    "# rand score\n",
    "DBSCAN_rc = metrics.rand_score(target, DBSCAN_labels)\n",
    "\n",
    "# Normalized Mutual Information\n",
    "DBSCAN_nmi = metrics.normalized_mutual_info_score(target, DBSCAN_labels)\n",
    "\n",
    "# Fowlkes-Mallows scores\n",
    "DBSCAN_fm  = metrics.fowlkes_mallows_score(target, DBSCAN_labels)\n",
    "\n",
    "\n",
    "print(f'rand score : {DBSCAN_rc}')\n",
    "print(f'Normalized Mutual Information score : {DBSCAN_nmi}')\n",
    "print(f'Fowlkes-Mallows score : {DBSCAN_fm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875dd22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN result\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "indx = 1\n",
    "for img in new_images:\n",
    "    img = np.array(img).reshape(64,64)\n",
    "    ax = fig.add_subplot(20,20,indx)\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "    # add label aka target aka cluster \n",
    "    ax.text(img.shape[0]/2, img.shape[1]/2, str(new_targets[indx-1]), fontsize = 20, color = 'red', fontweight='bold')\n",
    "    indx+=1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f370d60",
   "metadata": {},
   "source": [
    "# <font color = 'Blue'> Kmeans Clustering\n",
    "\n",
    "<hr>\n",
    "    \n",
    "Using sklearn KMeans algorithm, we can perform kmeans clustering on our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbab5869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "clustering = KMeans(n_clusters=  40)\n",
    "\n",
    "# Fit the model on dataset\n",
    "\n",
    "clustering.fit(data)\n",
    "\n",
    "# Clustering labels\n",
    "\n",
    "Kmeans_labels = clustering.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e28cd",
   "metadata": {},
   "source": [
    "##  <font color = 'Blue'> Visualizing the Results and lables\n",
    "    \n",
    "Just like previous clustering, clusters can be acquired using <code>.labels_</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "747f0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result , containg data, target and estimated cluster. \n",
    "Kmeans_results = pd.DataFrame({'data': data.tolist(),'y' : target, 'yhat': Kmeans_labels})\n",
    "# Sort the result so visulization is simpler \n",
    "# Sort based on the y estimate aka yhat \n",
    "# Result is the new cluster visualization\n",
    "Kmeans_results = Kmeans_results.sort_values(by='yhat')\n",
    "new_images = Kmeans_results['data']\n",
    "new_targets = np.array(Kmeans_results['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf809f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand score : 0.9718671679197995\n",
      "Normalized Mutual Information score : 0.7849243906540407\n",
      "Fowlkes-Mallows score : 0.4670101106143963\n"
     ]
    }
   ],
   "source": [
    "# rand score\n",
    "Kmeans_rc = metrics.rand_score(target, Kmeans_labels)\n",
    "\n",
    "# Normalized Mutual Information\n",
    "Kmeans_nmi = metrics.normalized_mutual_info_score(target, Kmeans_labels)\n",
    "\n",
    "# Fowlkes-Mallows scores\n",
    "Kmeans_fm  = metrics.fowlkes_mallows_score(target, Kmeans_labels)\n",
    "\n",
    "\n",
    "print(f'rand score : {Kmeans_rc}')\n",
    "print(f'Normalized Mutual Information score : {Kmeans_nmi}')\n",
    "print(f'Fowlkes-Mallows score : {Kmeans_fm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e14dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kmeans result\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "indx = 1\n",
    "for img in new_images:\n",
    "    img = np.array(img).reshape(64,64)\n",
    "    ax = fig.add_subplot(20,20,indx)\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "    # add label aka target aka cluster \n",
    "    ax.text(img.shape[0]/2, img.shape[1]/2, str(new_targets[indx-1]), fontsize = 20, color = 'red', fontweight='bold')\n",
    "    indx+=1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15abcc0",
   "metadata": {},
   "source": [
    "# <font color = 'Blue'> Spectral Clustering from scratch\n",
    "\n",
    "<hr>\n",
    "\n",
    "This is a special type of clusterin and requires a few steps to complete its implementation. We are not using the sklearn SpectralClustering package, therefore this clustering method is written from scratch. \n",
    "\n",
    "There are a few steps which we need to follow :\n",
    "\n",
    "\n",
    "**Note : The algorithm used for spectral can be found at Data Mining and Analysis_ Fundamental Concepts and Algorithms [Zaki & Meira 2014-05-12] Spectral Clustering page 459**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70567330",
   "metadata": {},
   "source": [
    "##  <font color = 'Blue'> 1. Construct Similarity matrix \n",
    "\n",
    "This is essentially our graph represented in a matrix. We need to create a similarity between data point (sample).  There are various methods to do so, such as :  RBF, KNN, OMP , etc. \n",
    "\n",
    "Since most of our methods work around distance matrix, we can make use of scipy to obtain such matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38435f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pariwise distance matrix between x_i,x_j where x_i and x_j are both in data (i,j : 1 2 ... N)\n",
    "# It returns the || X_i - X_j ||_2\n",
    "# It is more practical to use its squared value\n",
    "distance = distance_matrix(data,data)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c233de",
   "metadata": {},
   "source": [
    "### <font color = 'Blue'> 1.1 Similarity matrix using RBF\n",
    "\n",
    "$$\n",
    "W_{i,j} = \\begin{cases} \n",
    "\\exp^{(\\frac{-||x_i-x_j||_2^2}{\\sigma})} \\hspace{5mm} if \\hspace{3mm} \\exp^{(\\frac{-||x_i-x_j||_2^2}{\\sigma})} > \\delta \\\\\n",
    "0 \\hspace{2.5cm} O.W\n",
    "\\end{cases}\n",
    "\\hspace{3cm}\n",
    "W\\in R^{N\\times N}\n",
    "$$\n",
    "\n",
    "where you can choose these $\\sigma$ and $\\delta$ manually. They are usally set to be the mean distance.\n",
    "\n",
    "Since $W_{i,i}$ is 1 and we don't have loops, we replace them with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22d1e785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W_rbf = np.zeros((data.shape[0],data.shape[0]))\n",
    "gamma = 1/np.mean(distance)\n",
    "# delta is obtained manually\n",
    "# The method used to obtain delta is:\n",
    "# First consider delta = 0 and calculate W_rbf\n",
    "# Then set delta as np.mean(W_rbf - np.diag([1 for i in range(400)]))\n",
    "# Calculate W_rbf again using the new delta\n",
    "delta = 0.39468645906616884\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[0]):\n",
    "        if np.exp(-1*(gamma)*distance[i][j]) > delta:\n",
    "            W_rbf[i][j] = np.exp(-1*(gamma)*distance[i][j])\n",
    "            # W_i,i = 0\n",
    "            if i==j:\n",
    "                W_rbf[i][j] = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46645458",
   "metadata": {},
   "source": [
    "#### <font color = 'Blue'> Visualization using NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3132de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "G =  nx.Graph()\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[0]):\n",
    "        if W_rbf[i][j] !=0 :\n",
    "            G.add_edge(i,j)\n",
    "nx.draw(G, edge_color='skyblue', node_color='blue', node_size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced6c7e",
   "metadata": {},
   "source": [
    "### <font color = 'Blue'> 1.2 Similarity matrix using KNN\n",
    "\n",
    "Consider K nearest neighbours problem. The similarity matrix using KNN is as follow :\n",
    "\n",
    "$$\n",
    "N_k(X_i) = \\left\\{X_j | X_j\\text{  is within k nearest neighbours of X_i}\\right\\}\n",
    "$$\n",
    "\n",
    "Using the method above, we can sort each row of distance matrix using np.sort; Then find the KNN and their respected indices. Since there is a 0 in distance matrix (distance of $X_i$ with $X_i$), we ignore the 0 case.  N is the KNN indices matrix.\n",
    "\n",
    "$$\n",
    "\\bar{W_{i,j}} =  \\begin{cases} \n",
    "\\bar{W_{i,j}} \\hspace{5mm} if \\hspace{3mm} X_j \\in N_k(X_i) \\\\\n",
    "0 \\hspace{2.5cm} O.W\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "and $\\bar{W_{i,j}}$ can be $1$ or we can use weighted values such as $\\exp^{(\\frac{-||x_i-x_j||_2^2}{\\sigma})}$.\n",
    "\n",
    "The problem is that $\\bar{W}$ is not symmetric; Therfore :\n",
    "\n",
    "$$\n",
    "W_{i,j} = \\frac{\\bar{W_{i,j}} + \\bar{W_{j,i}}}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e79e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = []\n",
    "K = 5\n",
    "\n",
    "# Step 1 : Find N \n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    # sort distance matrix on data sample i\n",
    "    sorted_d = np.sort(distance[i])\n",
    "    knn_distance = sorted_d[:K+1]\n",
    "    # find index of each distance\n",
    "    index = []\n",
    "    for _d in knn_distance:\n",
    "        # ignore _d == 0\n",
    "        if _d == 0:\n",
    "            continue\n",
    "        for j in range(data.shape[0]):\n",
    "            if distance[i][j] == _d:\n",
    "                index.append(j)\n",
    "    \n",
    "    # append index to N\n",
    "    N.append(index)\n",
    "    \n",
    "# Step 2 : construct Wbar\n",
    "\n",
    "Wbar = np.zeros((data.shape[0],data.shape[0]))\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[0]):\n",
    "        if j in N[i]:\n",
    "            # define a weight\n",
    "            #Wbar[i][j] = 1\n",
    "            Wbar[i][j] = np.exp(-1*gamma*distance[i][j])\n",
    "            \n",
    "\n",
    "# Step 3 : Similarity matrix using KNN : W\n",
    "W_knn = np.zeros((data.shape[0],data.shape[0]))\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[0]):\n",
    "        W_knn[i][j] = (Wbar[i][j] + Wbar[j][i])/2\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b20ae",
   "metadata": {},
   "source": [
    "#### <font color = 'Blue'> Visualization using NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "G =  nx.Graph()\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[0]):\n",
    "        if W_knn[i][j] !=0 :\n",
    "            G.add_edge(i,j)\n",
    "nx.draw(G, edge_color='skyblue', node_color='blue', node_size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a7a99f",
   "metadata": {},
   "source": [
    "### <font color = 'Blue'> 1.3 Similarity matrix using OMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "047549e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't know this part . using a different version of KNN (just a temporary approach)\n",
    "\n",
    "N = []\n",
    "K = 5\n",
    "\n",
    "# Step 1 : Find N \n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    # sort distance matrix on data sample i\n",
    "    sorted_d = np.sort(distance[i])\n",
    "    knn_distance = sorted_d[:K+1]\n",
    "    # find index of each distance\n",
    "    index = []\n",
    "    for _d in knn_distance:\n",
    "        # ignore _d == 0\n",
    "        if _d == 0:\n",
    "            continue\n",
    "        for j in range(data.shape[0]):\n",
    "            if distance[i][j] == _d:\n",
    "                index.append(j)\n",
    "    \n",
    "    # append index to N\n",
    "    N.append(index)\n",
    "    \n",
    "# Step 2 : construct Wbar\n",
    "\n",
    "Wbar = np.zeros((data.shape[0],data.shape[0]))\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[0]):\n",
    "        if j in N[i]:\n",
    "            # define a weight\n",
    "            Wbar[i][j] = 1\n",
    "            #Wbar[i][j] = np.exp(-1*gamma*distance[i][j])\n",
    "            \n",
    "\n",
    "# Step 3 : Similarity matrix using KNN : W\n",
    "W_omp= np.zeros((data.shape[0],data.shape[0]))\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[0]):\n",
    "        W_omp[i][j] = (Wbar[i][j] + Wbar[j][i])/2\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1595c9f6",
   "metadata": {},
   "source": [
    "#### <font color = 'Blue'> Visualization using NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "G =  nx.Graph()\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[0]):\n",
    "        if W_omp[i][j] !=0 :\n",
    "            G.add_edge(i,j)\n",
    "nx.draw(G, edge_color='skyblue', node_color='blue', node_size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da59ed3",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'> 2.  Compute Laplacian\n",
    "\n",
    "To Compute Laplacian, we need to calculate Degree matrix :\n",
    "\n",
    "$$\n",
    "D_i = \\sum_{j=1}^{N} W_{i,j}\n",
    "$$\n",
    "\n",
    "Using D, we can calculate Laplacian matrix via :\n",
    "\n",
    "$$\n",
    "L = D - W\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$ \n",
    "L^s = D^{-\\frac{1}{2}} L D^{-\\frac{1}{2}} \\hspace{1cm} L^a = D^{-1} L\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3508c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree using rbf similarity matrix\n",
    "\n",
    "Degree_rbf = np.zeros((data.shape[0],data.shape[0]))\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    d = 0\n",
    "    for j in range(data.shape[0]):\n",
    "        d+= W_rbf[i][j]\n",
    "    Degree_rbf[i][i] = d\n",
    "\n",
    "\n",
    "# Degree using KNN similarity  matrix\n",
    "\n",
    "Degree_knn = np.zeros((data.shape[0],data.shape[0]))\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    d = 0\n",
    "    for j in range(data.shape[0]):\n",
    "        d+= W_knn[i][j]\n",
    "    Degree_knn[i][i] = d\n",
    "\n",
    "# Degree using OMP similarity matrix\n",
    "\n",
    "Degree_omp = np.zeros((data.shape[0],data.shape[0])) \n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    d = 0\n",
    "    for j in range(data.shape[0]):\n",
    "        d+= W_omp[i][j]\n",
    "    Degree_omp[i][i] = d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f0ce99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian using rbf \n",
    "\n",
    "L_rbf = Degree_rbf -  W_rbf\n",
    "\n",
    "L_rbf_a = np.matmul(np.linalg.inv(Degree_rbf), L_rbf)\n",
    "L_rbf_s = np.matmul(\n",
    "    np.matmul(np.sqrt(np.linalg.matrix_power(Degree_rbf,-1)), L_rbf)\n",
    "    ,np.sqrt(np.linalg.matrix_power(Degree_rbf,-1)))\n",
    "\n",
    "# Laplacian using KNN\n",
    "\n",
    "L_knn = Degree_knn -  W_knn\n",
    "\n",
    "L_knn_a = np.matmul(np.linalg.inv(Degree_knn), L_knn)\n",
    "L_knn_s = np.matmul(\n",
    "    np.matmul(np.sqrt(np.linalg.matrix_power(Degree_knn,-1)), L_knn)\n",
    "    ,np.sqrt(np.linalg.matrix_power(Degree_knn,-1)))\n",
    "\n",
    "# Laplacian using OMP\n",
    "\n",
    "L_omp = Degree_omp -  W_omp\n",
    "\n",
    "L_omp_a = np.matmul(np.linalg.inv(Degree_omp), L_omp)\n",
    "L_omp_s = np.matmul(\n",
    "    np.matmul(np.sqrt(np.linalg.matrix_power(Degree_omp,-1)), L_omp)\n",
    "    ,np.sqrt(np.linalg.matrix_power(Degree_omp,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cae3b5",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'> 3. Compute Eigen values and Eigen Vectors\n",
    "\n",
    "We need k smallest eigen values and eigen vectors to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acbfb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF \n",
    "\n",
    "# Eigen values and vector using Laplacian RBF (L)\n",
    "\n",
    "eig_lambda_rbf, eig_vec_rbf = np.linalg.eig(L_rbf)\n",
    "eig_rbf = pd.DataFrame({'lambda' : eig_lambda_rbf , 'vector' : eig_vec_rbf.tolist()})\n",
    "eig_rbf = eig_rbf.sort_values(by = 'lambda')\n",
    "\n",
    "# Eigen values and vector using Laplacian RBF  (L^s)\n",
    "\n",
    "eig_lambda_rbf_s, eig_vec_rbf_s = np.linalg.eig(L_rbf_s)\n",
    "eig_rbf_s = pd.DataFrame({'lambda' : eig_lambda_rbf_s , 'vector' : eig_vec_rbf_s.tolist()})\n",
    "eig_rbf_s = eig_rbf_s.sort_values(by = 'lambda')\n",
    "\n",
    "# Eigen values and vector using Laplacian RBF  (L^a)\n",
    "\n",
    "eig_lambda_rbf_a, eig_vec_rbf_a = np.linalg.eig(L_rbf_a)\n",
    "eig_rbf_a = pd.DataFrame({'lambda' : eig_lambda_rbf_a , 'vector' : eig_vec_rbf_a.tolist()})\n",
    "eig_rbf_a = eig_rbf_a.sort_values(by = 'lambda')\n",
    "\n",
    "# KNN\n",
    "\n",
    "# Eigen values and vector using Laplacian KNN (L)\n",
    "\n",
    "eig_lambda_knn, eig_vec_knn = np.linalg.eig(L_knn)\n",
    "eig_knn = pd.DataFrame({'lambda' : eig_lambda_knn , 'vector' : eig_vec_knn.tolist()})\n",
    "eig_knn = eig_knn.sort_values(by = 'lambda')\n",
    "\n",
    "# Eigen values and vector using Laplacian KNN  (L^s)\n",
    "\n",
    "eig_lambda_knn_s, eig_vec_knn_s = np.linalg.eig(L_knn_s)\n",
    "eig_knn_s = pd.DataFrame({'lambda' : eig_lambda_knn_s , 'vector' : eig_vec_knn_s.tolist()})\n",
    "eig_knn_s = eig_knn_s.sort_values(by = 'lambda')\n",
    "\n",
    "# Eigen values and vector using Laplacian KNN  (L^a)\n",
    "\n",
    "eig_lambda_knn_a, eig_vec_knn_a = np.linalg.eig(L_knn_a)\n",
    "eig_knn_a = pd.DataFrame({'lambda' : eig_lambda_knn_a , 'vector' : eig_vec_knn_a.tolist()})\n",
    "eig_knn_a = eig_knn_a.sort_values(by = 'lambda')\n",
    "\n",
    "\n",
    "# OMP\n",
    "\n",
    "# Eigen values and vector using Laplacian OMP (L)\n",
    "\n",
    "eig_lambda_omp, eig_vec_omp = np.linalg.eig(L_omp)\n",
    "eig_omp = pd.DataFrame({'lambda' : eig_lambda_omp , 'vector' : eig_vec_omp.tolist()})\n",
    "eig_omp = eig_omp.sort_values(by = 'lambda')\n",
    "\n",
    "# Eigen values and vector using Laplacian OMP  (L^s)\n",
    "\n",
    "eig_lambda_omp_s, eig_vec_omp_s = np.linalg.eig(L_omp_s)\n",
    "eig_omp_s = pd.DataFrame({'lambda' : eig_lambda_omp_s , 'vector' : eig_vec_omp_s.tolist()})\n",
    "eig_omp_s = eig_omp_s.sort_values(by = 'lambda')\n",
    "\n",
    "# Eigen values and vector using Laplacian OMP  (L^a)\n",
    "\n",
    "eig_lambda_omp_a, eig_vec_omp_a = np.linalg.eig(L_omp_a)\n",
    "eig_omp_a = pd.DataFrame({'lambda' : eig_lambda_omp_a , 'vector' : eig_vec_omp_a.tolist()})\n",
    "eig_omp_a = eig_omp_a.sort_values(by = 'lambda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd4d70",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'> 4. Obtain U and Y \n",
    "\n",
    "Y is a normalized form of U."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c644f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF \n",
    "\n",
    "# RBF L == > Ratio Cut\n",
    "\n",
    "U_rbf = np.zeros((data.shape[0],40))\n",
    "vectors = np.array(eig_rbf.iloc[:40]['vector'])\n",
    "for j in range(40):\n",
    "    for i in range(data.shape[0]):\n",
    "        U_rbf[i][j] =  vectors[j][i]\n",
    "        \n",
    "Y_rbf = np.matmul(np.linalg.inv(Degree_rbf), U_rbf)\n",
    "\n",
    "# RBF L^a ==> Normalized Cut\n",
    "\n",
    "U_rbf_a = np.zeros((data.shape[0],40))\n",
    "vectors = np.array(eig_rbf_a.iloc[:40]['vector'])\n",
    "for j in range(40):\n",
    "    for i in range(data.shape[0]):\n",
    "        U_rbf_a[i][j] =  vectors[j][i]\n",
    "        \n",
    "Y_rbf_a = U_rbf_a\n",
    "\n",
    "\n",
    "# KNN \n",
    "\n",
    "# KNN L == > Ratio Cut\n",
    "\n",
    "U_knn = np.zeros((data.shape[0],40))\n",
    "vectors = np.array(eig_knn.iloc[:40]['vector'])\n",
    "for j in range(40):\n",
    "    for i in range(data.shape[0]):\n",
    "        U_knn[i][j] =  vectors[j][i]\n",
    "        \n",
    "Y_knn = np.matmul(np.linalg.inv(Degree_knn), U_knn)\n",
    "\n",
    "# KNN L^a ==> Normalized Cut\n",
    "\n",
    "U_knn_a = np.zeros((data.shape[0],40))\n",
    "vectors = np.array(eig_knn_a.iloc[:40]['vector'])\n",
    "for j in range(40):\n",
    "    for i in range(data.shape[0]):\n",
    "        U_knn_a[i][j] =  vectors[j][i]\n",
    "        \n",
    "Y_knn_a = U_knn_a\n",
    "\n",
    "# OMP\n",
    "\n",
    "# OMP L == > Ratio Cut\n",
    "\n",
    "U_omp = np.zeros((data.shape[0],40))\n",
    "vectors = np.array(eig_omp.iloc[:40]['vector'])\n",
    "for j in range(40):\n",
    "    for i in range(data.shape[0]):\n",
    "        U_omp[i][j] =  vectors[j][i]\n",
    "        \n",
    "Y_omp = np.matmul(np.linalg.inv(Degree_omp), U_omp)\n",
    "\n",
    "# OMP L^a ==> Normalized Cut\n",
    "\n",
    "U_omp_a = np.zeros((data.shape[0],40))\n",
    "vectors = np.array(eig_omp_a.iloc[:40]['vector'])\n",
    "for j in range(40):\n",
    "    for i in range(data.shape[0]):\n",
    "        U_omp_a[i][j] =  np.abs(vectors[j][i])\n",
    "        \n",
    "Y_omp_a = U_omp_a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d01bd",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'> 5. Perform Kmeans on Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cfa39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF\n",
    "\n",
    "# Ratio Cut\n",
    "\n",
    "Kmean_ratio_cut_rbf = KMeans(n_clusters=40).fit(Y_rbf)\n",
    "\n",
    "# Normalized Cut\n",
    "\n",
    "Kmean_normalized_cut_rbf = KMeans(n_clusters=40).fit(Y_rbf_a)\n",
    "\n",
    "\n",
    "# KNN\n",
    "\n",
    "# Ratio Cut\n",
    "\n",
    "Kmean_ratio_cut_knn = KMeans(n_clusters=40).fit(Y_knn)\n",
    "\n",
    "# Normalized Cut\n",
    "\n",
    "Kmean_normalized_cut_knn = KMeans(n_clusters=40).fit(Y_knn_a)\n",
    "\n",
    "# OMP\n",
    "\n",
    "# Ratio Cut\n",
    "\n",
    "Kmean_ratio_cut_omp = KMeans(n_clusters=40).fit(Y_omp)\n",
    "\n",
    "# Normalized Cut\n",
    "\n",
    "Kmean_normalized_cut_omp = KMeans(n_clusters=40).fit(Y_omp_a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d03f9",
   "metadata": {},
   "source": [
    "# <font color = 'Blue'> Visualizing the result using Spectral Clustering\n",
    "\n",
    "<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f590f9",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'> RBF (ratio Cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66c99c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result , containg data, target and estimated cluster. \n",
    "spectral_results_rbf_ratio_cut = pd.DataFrame(\n",
    "    {'data': data.tolist(),'y' : target, 'yhat': Kmean_ratio_cut_rbf.labels_}\n",
    "    )\n",
    "# Sort the result so visulization is simpler \n",
    "# Sort based on the y estimate aka yhat \n",
    "# Result is the new cluster visualization\n",
    "spectral_results_rbf_ratio_cut = spectral_results_rbf_ratio_cut.sort_values(by='yhat')\n",
    "new_images = spectral_results_rbf_ratio_cut['data']\n",
    "new_targets = np.array(spectral_results_rbf_ratio_cut['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06c44244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand score : 0.3316165413533835\n",
      "Normalized Mutual Information score : 0.2280264029982406\n",
      "Fowlkes-Mallows score : 0.1309011177181072\n"
     ]
    }
   ],
   "source": [
    "# rand score\n",
    "spectral_rbf_ratio_cut_rc = metrics.rand_score(target, Kmean_ratio_cut_rbf.labels_)\n",
    "\n",
    "# Normalized Mutual Information\n",
    "spectral_rbf_ratio_cut_nmi = metrics.normalized_mutual_info_score(target, Kmean_ratio_cut_rbf.labels_)\n",
    "\n",
    "# Fowlkes-Mallows scores\n",
    "spectral_rbf_ratio_cut_fm  = metrics.fowlkes_mallows_score(target, Kmean_ratio_cut_rbf.labels_)\n",
    "\n",
    "\n",
    "print(f'rand score : {spectral_rbf_ratio_cut_rc}')\n",
    "print(f'Normalized Mutual Information score : {spectral_rbf_ratio_cut_nmi}')\n",
    "print(f'Fowlkes-Mallows score : {spectral_rbf_ratio_cut_fm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Clustering using RBF and Ratio Cut result\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "indx = 1\n",
    "for img in new_images:\n",
    "    img = np.array(img).reshape(64,64)\n",
    "    ax = fig.add_subplot(20,20,indx)\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "    # add label aka target aka cluster \n",
    "    ax.text(img.shape[0]/2, img.shape[1]/2, str(new_targets[indx-1]), fontsize = 20, color = 'red', fontweight='bold')\n",
    "    indx+=1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9314c664",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'> RBF (Normalized Cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5414cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result , containg data, target and estimated cluster. \n",
    "spectral_results_rbf_normalized_cut = pd.DataFrame(\n",
    "    {'data': data.tolist(),'y' : target, 'yhat': Kmean_normalized_cut_rbf.labels_}\n",
    "    )\n",
    "\n",
    "# Sort the result so visulization is simpler \n",
    "# Sort based on the y estimate aka yhat \n",
    "# Result is the new cluster visualization\n",
    "spectral_results_rbf_normalized_cut = spectral_results_rbf_normalized_cut.sort_values(by='yhat')\n",
    "new_images = spectral_results_rbf_normalized_cut['data']\n",
    "new_targets = np.array(spectral_results_rbf_normalized_cut['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4dc105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand score : 0.9306015037593985\n",
      "Normalized Mutual Information score : 0.3670391924521477\n",
      "Fowlkes-Mallows score : 0.042303409177924384\n"
     ]
    }
   ],
   "source": [
    "# rand score\n",
    "spectral_rbf_normalized_cut_rc = metrics.rand_score(target, Kmean_normalized_cut_rbf.labels_)\n",
    "\n",
    "# Normalized Mutual Information\n",
    "spectral_rbf_normalized_cut_nmi = metrics.normalized_mutual_info_score(target, Kmean_normalized_cut_rbf.labels_)\n",
    "\n",
    "# Fowlkes-Mallows scores\n",
    "spectral_rbf_normalized_cut_fm  = metrics.fowlkes_mallows_score(target, Kmean_normalized_cut_rbf.labels_)\n",
    "\n",
    "\n",
    "print(f'rand score : {spectral_rbf_normalized_cut_rc}')\n",
    "print(f'Normalized Mutual Information score : {spectral_rbf_normalized_cut_nmi}')\n",
    "print(f'Fowlkes-Mallows score : {spectral_rbf_normalized_cut_fm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Clustering using RBF and Ratio Cut result\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "indx = 1\n",
    "for img in new_images:\n",
    "    img = np.array(img).reshape(64,64)\n",
    "    ax = fig.add_subplot(20,20,indx)\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "    # add label aka target aka cluster \n",
    "    ax.text(img.shape[0]/2, img.shape[1]/2, str(new_targets[indx-1]), fontsize = 20, color = 'red', fontweight='bold')\n",
    "    indx+=1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3813fe",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'> KNN (Ratio Cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5e9060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result , containg data, target and estimated cluster. \n",
    "spectral_results_KNN_ratio_cut = pd.DataFrame(\n",
    "    {'data': data.tolist(),'y' : target, 'yhat': Kmean_ratio_cut_knn.labels_}\n",
    "    )\n",
    "\n",
    "# Sort the result so visulization is simpler \n",
    "# Sort based on the y estimate aka yhat \n",
    "# Result is the new cluster visualization\n",
    "spectral_results_KNN_ratio_cut = spectral_results_KNN_ratio_cut.sort_values(by='yhat')\n",
    "new_images = spectral_results_KNN_ratio_cut['data']\n",
    "new_targets = np.array(spectral_results_KNN_ratio_cut['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa6eb568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand score : 0.4203508771929825\n",
      "Normalized Mutual Information score : 0.24734926597144732\n",
      "Fowlkes-Mallows score : 0.11918102465610414\n"
     ]
    }
   ],
   "source": [
    "# rand score\n",
    "spectral_knn_ratio_cut_rc = metrics.rand_score(target, Kmean_ratio_cut_knn.labels_)\n",
    "\n",
    "# Normalized Mutual Information\n",
    "spectral_knn_ratio_cut_nmi = metrics.normalized_mutual_info_score(target, Kmean_ratio_cut_knn.labels_)\n",
    "\n",
    "# Fowlkes-Mallows scores\n",
    "spectral_knn_ratio_cut_fm  = metrics.fowlkes_mallows_score(target, Kmean_ratio_cut_knn.labels_)\n",
    "\n",
    "\n",
    "print(f'rand score : {spectral_knn_ratio_cut_rc}')\n",
    "print(f'Normalized Mutual Information score : {spectral_knn_ratio_cut_nmi}')\n",
    "print(f'Fowlkes-Mallows score : {spectral_knn_ratio_cut_fm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Clustering using RBF and Ratio Cut result\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "indx = 1\n",
    "for img in new_images:\n",
    "    img = np.array(img).reshape(64,64)\n",
    "    ax = fig.add_subplot(20,20,indx)\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "    # add label aka target aka cluster \n",
    "    ax.text(img.shape[0]/2, img.shape[1]/2, str(new_targets[indx-1]), fontsize = 20, color = 'red', fontweight='bold')\n",
    "    indx+=1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d1c45a",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'> KNN (Normalized Cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b2bf525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result , containg data, target and estimated cluster. \n",
    "spectral_results_knn_normalized_cut = pd.DataFrame(\n",
    "    {'data': data.tolist(),'y' : target, 'yhat': Kmean_normalized_cut_knn.labels_}\n",
    "    )\n",
    "\n",
    "# Sort the result so visulization is simpler \n",
    "# Sort based on the y estimate aka yhat \n",
    "# Result is the new cluster visualization\n",
    "spectral_results_knn_normalized_cut = spectral_results_knn_normalized_cut.sort_values(by='yhat')\n",
    "new_images = spectral_results_knn_normalized_cut['data']\n",
    "new_targets = np.array(spectral_results_knn_normalized_cut['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea9b0740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand score : 0.7755388471177945\n",
      "Normalized Mutual Information score : 0.31797891149456237\n",
      "Fowlkes-Mallows score : 0.08378126873670495\n"
     ]
    }
   ],
   "source": [
    "# rand score\n",
    "spectral_knn_normalized_cut_rc = metrics.rand_score(target, Kmean_normalized_cut_knn.labels_)\n",
    "\n",
    "# Normalized Mutual Information\n",
    "spectral_knn_normalized_cut_nmi = metrics.normalized_mutual_info_score(target, Kmean_normalized_cut_knn.labels_)\n",
    "\n",
    "# Fowlkes-Mallows scores\n",
    "spectral_knn_normalized_cut_fm  = metrics.fowlkes_mallows_score(target, Kmean_normalized_cut_knn.labels_)\n",
    "\n",
    "\n",
    "print(f'rand score : {spectral_knn_normalized_cut_rc}')\n",
    "print(f'Normalized Mutual Information score : {spectral_knn_normalized_cut_nmi}')\n",
    "print(f'Fowlkes-Mallows score : {spectral_knn_normalized_cut_fm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Clustering using RBF and Ratio Cut result\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "indx = 1\n",
    "for img in new_images:\n",
    "    img = np.array(img).reshape(64,64)\n",
    "    ax = fig.add_subplot(20,20,indx)\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "    # add label aka target aka cluster \n",
    "    ax.text(img.shape[0]/2, img.shape[1]/2, str(new_targets[indx-1]), fontsize = 20, color = 'red', fontweight='bold')\n",
    "    indx+=1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5574140",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'> OMP (Ratio Cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db1c4ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result , containg data, target and estimated cluster. \n",
    "spectral_results_omp_ratio_cut = pd.DataFrame(\n",
    "    {'data': data.tolist(),'y' : target, 'yhat': Kmean_ratio_cut_omp.labels_}\n",
    "    )\n",
    "\n",
    "# Sort the result so visulization is simpler \n",
    "# Sort based on the y estimate aka yhat \n",
    "# Result is the new cluster visualization\n",
    "spectral_results_omp_ratio_cut = spectral_results_omp_ratio_cut.sort_values(by='yhat')\n",
    "new_images = spectral_results_omp_ratio_cut['data']\n",
    "new_targets = np.array(spectral_results_omp_ratio_cut['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cb4b13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand score : 0.5425814536340852\n",
      "Normalized Mutual Information score : 0.274707709381671\n",
      "Fowlkes-Mallows score : 0.1076602284324958\n"
     ]
    }
   ],
   "source": [
    "# rand score\n",
    "spectral_omp_ratio_cut_rc = metrics.rand_score(target, Kmean_ratio_cut_omp.labels_)\n",
    "\n",
    "# Normalized Mutual Information\n",
    "spectral_omp_ratio_cut_nmi = metrics.normalized_mutual_info_score(target, Kmean_ratio_cut_omp.labels_)\n",
    "\n",
    "# Fowlkes-Mallows scores\n",
    "spectral_omp_ratio_cut_fm  = metrics.fowlkes_mallows_score(target, Kmean_ratio_cut_omp.labels_)\n",
    "\n",
    "\n",
    "print(f'rand score : {spectral_omp_ratio_cut_rc}')\n",
    "print(f'Normalized Mutual Information score : {spectral_omp_ratio_cut_nmi}')\n",
    "print(f'Fowlkes-Mallows score : {spectral_omp_ratio_cut_fm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da353c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Clustering using RBF and Ratio Cut result\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "indx = 1\n",
    "for img in new_images:\n",
    "    img = np.array(img).reshape(64,64)\n",
    "    ax = fig.add_subplot(20,20,indx)\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "    # add label aka target aka cluster \n",
    "    ax.text(img.shape[0]/2, img.shape[1]/2, str(new_targets[indx-1]), fontsize = 20, color = 'red', fontweight='bold')\n",
    "    indx+=1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b216c6dd",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'> OMP (Normalized Cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2597ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result , containg data, target and estimated cluster. \n",
    "spectral_results_omp_normalized_cut = pd.DataFrame(\n",
    "    {'data': data.tolist(),'y' : target, 'yhat': Kmean_normalized_cut_omp.labels_}\n",
    "    )\n",
    "\n",
    "# Sort the result so visulization is simpler \n",
    "# Sort based on the y estimate aka yhat \n",
    "# Result is the new cluster visualization\n",
    "spectral_results_omp_normalized_cut = spectral_results_omp_normalized_cut.sort_values(by='yhat')\n",
    "new_images = spectral_results_omp_normalized_cut['data']\n",
    "new_targets = np.array(spectral_results_omp_normalized_cut['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42b51a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand score : 0.9239724310776942\n",
      "Normalized Mutual Information score : 0.46727716021533255\n",
      "Fowlkes-Mallows score : 0.11984657155401175\n"
     ]
    }
   ],
   "source": [
    "# rand score\n",
    "spectral_omp_normalized_cut_rc = metrics.rand_score(target, Kmean_normalized_cut_omp.labels_)\n",
    "\n",
    "# Normalized Mutual Information\n",
    "spectral_omp_normalized_cut_nmi = metrics.normalized_mutual_info_score(target, Kmean_normalized_cut_omp.labels_)\n",
    "\n",
    "# Fowlkes-Mallows scores\n",
    "spectral_omp_normalized_cut_fm  = metrics.fowlkes_mallows_score(target, Kmean_normalized_cut_omp.labels_)\n",
    "\n",
    "\n",
    "print(f'rand score : {spectral_omp_normalized_cut_rc}')\n",
    "print(f'Normalized Mutual Information score : {spectral_omp_normalized_cut_nmi}')\n",
    "print(f'Fowlkes-Mallows score : {spectral_omp_normalized_cut_fm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134433af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Clustering using RBF and Ratio Cut result\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "indx = 1\n",
    "for img in new_images:\n",
    "    img = np.array(img).reshape(64,64)\n",
    "    ax = fig.add_subplot(20,20,indx)\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    ax.grid(False)\n",
    "    ax.axis('off')\n",
    "    # add label aka target aka cluster \n",
    "    ax.text(img.shape[0]/2, img.shape[1]/2, str(new_targets[indx-1]), fontsize = 20, color = 'red', fontweight='bold')\n",
    "    indx+=1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
